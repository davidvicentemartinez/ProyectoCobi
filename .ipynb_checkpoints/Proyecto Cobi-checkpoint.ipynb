{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math as m\n",
    "import random\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras import optimizers, regularizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "33\n",
      "805\n",
      "201\n"
     ]
    }
   ],
   "source": [
    "A = []\n",
    "for filename in glob.glob('Fotos Cobi/*.jpeg'):\n",
    "    img = load_img(filename, target_size=(150, 150)) \n",
    "    A.append(img_to_array(img))\n",
    "B = []\n",
    "for filename in glob.glob('Fotos Gatos/*.jpg'):\n",
    "    img = load_img(filename, target_size=(150, 150)) \n",
    "    B.append(img_to_array(img))\n",
    "\n",
    "len_A_tr = m.floor(len(A)*0.8)\n",
    "len_A_ts = m.floor(len(A)*0.2)\n",
    "len_A_tr = len_A_tr + (len(A) - len_A_tr - len_A_ts)\n",
    "\n",
    "len_B_tr = m.floor(len(B)*0.8)\n",
    "len_B_ts = m.floor(len(B)*0.2)\n",
    "len_B_tr = len_B_tr + (len(B) - len_B_tr - len_B_ts)\n",
    "\n",
    "random.shuffle(A)\n",
    "random.shuffle(B)\n",
    "\n",
    "A_tr = []\n",
    "B_tr = []\n",
    "A_ts = []\n",
    "B_ts = []\n",
    "for i in range(0,len_A_tr):\n",
    "    A_tr.append(A.pop(0))\n",
    "for i in range(0,len_A_ts):\n",
    "    A_ts.append(A.pop(0))\n",
    "for i in range(0,len_B_tr):\n",
    "    B_tr.append(B.pop(0))\n",
    "for i in range(0,len_B_ts):\n",
    "    B_ts.append(B.pop(0))\n",
    "\n",
    "print(len(A_tr))\n",
    "print(len(A_ts))\n",
    "print(len(B_tr))\n",
    "print(len(B_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "for f in glob.glob('Fotos Cobi Augmentation (tr)/*.jpeg'):\n",
    "    os.remove(f)\n",
    "for f in glob.glob('Fotos Cobi Augmentation (ts)/*.jpeg'):\n",
    "    os.remove(f)\n",
    "    \n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        brightness_range = (0.5, 1.5))\n",
    "\n",
    "for x in A_tr:\n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 1, \n",
    "                                save_to_dir ='Fotos Cobi Augmentation (tr)',  \n",
    "                                save_prefix ='image', save_format ='jpeg'): \n",
    "        i += 1\n",
    "        if i > 5: \n",
    "            break\n",
    "            \n",
    "for x in A_ts:\n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 1, \n",
    "                                save_to_dir ='Fotos Cobi Augmentation (ts)',  \n",
    "                                save_prefix ='image', save_format ='jpeg'): \n",
    "        i += 1\n",
    "        if i > 5: \n",
    "            break\n",
    "\n",
    "\n",
    "A_tr = []\n",
    "for filename in glob.glob('Fotos Cobi Augmentation (tr)/*.jpeg'):\n",
    "    img = load_img(filename, target_size=(150, 150)) \n",
    "    A_tr.append(img_to_array(img))\n",
    "    \n",
    "A_ts = []\n",
    "for filename in glob.glob('Fotos Cobi Augmentation (ts)/*.jpeg'):\n",
    "    img = load_img(filename, target_size=(150, 150)) \n",
    "    A_ts.append(img_to_array(img))\n",
    "    \n",
    "print(len(A_tr))\n",
    "print(len(A_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "len_tr = m.floor((len(X) + len(Y)) * 0.8)\n",
    "len_ts = m.floor((len(X) + len(Y)) * 0.2)\n",
    "len_tr = len_tr + (len(X) + len(Y) - len_tr - len_ts)\n",
    "\"\"\"\n",
    "\n",
    "X_tr = []\n",
    "Y_tr = []\n",
    "X_ts = []\n",
    "Y_ts = []\n",
    "\n",
    "X_tr = A_tr + B_tr\n",
    "X_ts = A_ts + B_ts\n",
    "\n",
    "for i in range(0,len(A_tr)):\n",
    "    Y_tr.append(0)\n",
    "for i in range(len(A_tr), len(B_tr) + len(A_tr)):\n",
    "    Y_tr.append(1)\n",
    "for i in range(0,len(A_ts)):\n",
    "    Y_ts.append(0)\n",
    "for i in range(len(A_ts), len(B_ts) + len(A_ts)):\n",
    "    Y_ts.append(1)\n",
    "      \n",
    "X_tr = np.array(X_tr)\n",
    "Y_tr = np.array(Y_tr)\n",
    "X_ts = np.array(X_ts)\n",
    "Y_ts = np.array(Y_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion del modelo\n",
    "img_width, img_height = 150, 150\n",
    "input_shape = (img_width, img_height, 3)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "#              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              optimizer=tf.keras.optimizers.RMSprop(),\n",
    "              metrics=['acc'])\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "acum_tr_acc = []\n",
    "acum_val_acc = []\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1588 samples, validate on 398 samples\n",
      "Epoch 1/30\n",
      "1588/1588 [==============================] - 28s 18ms/sample - loss: 67.3015 - acc: 0.5838 - val_loss: 0.6739 - val_acc: 0.6256\n",
      "Epoch 2/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 1.3608 - acc: 0.6751 - val_loss: 1.5266 - val_acc: 0.6055\n",
      "Epoch 3/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 2.5857 - acc: 0.7217 - val_loss: 0.5920 - val_acc: 0.6985\n",
      "Epoch 4/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 2.5365 - acc: 0.7047 - val_loss: 0.7927 - val_acc: 0.6407\n",
      "Epoch 5/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 1.5561 - acc: 0.6190 - val_loss: 0.6152 - val_acc: 0.6658\n",
      "Epoch 6/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.7240 - acc: 0.6241 - val_loss: 0.6012 - val_acc: 0.6633\n",
      "Epoch 7/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 1.0718 - acc: 0.6952 - val_loss: 0.5633 - val_acc: 0.6884\n",
      "Epoch 8/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.7267 - acc: 0.7664 - val_loss: 0.7500 - val_acc: 0.7412\n",
      "Epoch 9/30\n",
      "1588/1588 [==============================] - 25s 15ms/sample - loss: 0.6284 - acc: 0.7935 - val_loss: 0.6241 - val_acc: 0.7261\n",
      "Epoch 10/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.6241 - acc: 0.8205 - val_loss: 0.6841 - val_acc: 0.7286\n",
      "Epoch 11/30\n",
      "1588/1588 [==============================] - 25s 15ms/sample - loss: 0.8718 - acc: 0.8463 - val_loss: 1.3310 - val_acc: 0.7161\n",
      "Epoch 12/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.8389 - acc: 0.8722 - val_loss: 2.2938 - val_acc: 0.6960\n",
      "Epoch 13/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.8214 - acc: 0.8854 - val_loss: 1.1469 - val_acc: 0.7362\n",
      "Epoch 14/30\n",
      "1588/1588 [==============================] - 25s 16ms/sample - loss: 0.4133 - acc: 0.9030 - val_loss: 1.1373 - val_acc: 0.7412\n",
      "Epoch 15/30\n",
      "1588/1588 [==============================] - 26s 16ms/sample - loss: 1.0837 - acc: 0.8904 - val_loss: 2.1492 - val_acc: 0.7588\n",
      "Epoch 16/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.5453 - acc: 0.9106 - val_loss: 1.3364 - val_acc: 0.7337\n",
      "Epoch 17/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.7903 - acc: 0.9225 - val_loss: 1.9903 - val_acc: 0.7211\n",
      "Epoch 18/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.2674 - acc: 0.9452 - val_loss: 2.0508 - val_acc: 0.7739\n",
      "Epoch 19/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.6786 - acc: 0.9389 - val_loss: 4.5499 - val_acc: 0.6884\n",
      "Epoch 20/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.6588 - acc: 0.9358 - val_loss: 1.2705 - val_acc: 0.7337\n",
      "Epoch 21/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.7240 - acc: 0.9395 - val_loss: 1.8723 - val_acc: 0.7663\n",
      "Epoch 22/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.3932 - acc: 0.9465 - val_loss: 3.1516 - val_acc: 0.7613\n",
      "Epoch 23/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.3613 - acc: 0.9515 - val_loss: 2.0947 - val_acc: 0.7638\n",
      "Epoch 24/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.2733 - acc: 0.9591 - val_loss: 2.4855 - val_acc: 0.7714\n",
      "Epoch 25/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.6495 - acc: 0.9471 - val_loss: 2.0729 - val_acc: 0.7839\n",
      "Epoch 26/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.4455 - acc: 0.9641 - val_loss: 4.2721 - val_acc: 0.7839\n",
      "Epoch 27/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.4055 - acc: 0.9654 - val_loss: 5.0267 - val_acc: 0.6960\n",
      "Epoch 28/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.2664 - acc: 0.9704 - val_loss: 2.9761 - val_acc: 0.7739\n",
      "Epoch 29/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.2347 - acc: 0.9704 - val_loss: 4.4029 - val_acc: 0.7764\n",
      "Epoch 30/30\n",
      "1588/1588 [==============================] - 24s 15ms/sample - loss: 0.2494 - acc: 0.9748 - val_loss: 2.8730 - val_acc: 0.7864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2bccdeda208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_tr, Y_tr,\n",
    "    batch_size=batch_size,\n",
    "    epochs=5,\n",
    "    validation_data=(X_ts, Y_ts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = load_img('prueba_Cobi1.jpeg', target_size=(150, 150))\n",
    "img2 = load_img('prueba_Cobi2.jpeg', target_size=(150, 150))\n",
    "img5 = load_img('prueba_Cobi3.jpeg', target_size=(150, 150))\n",
    "\n",
    "img3 = load_img('prueba_Gato1.jpg', target_size=(150, 150))\n",
    "img4 = load_img('prueba_Gato2.jpg', target_size=(150, 150))\n",
    "\n",
    "F = []\n",
    "F.append(img1)\n",
    "F.append(img2)\n",
    "F.append(img3)\n",
    "F.append(img4)\n",
    "F.append(img5)\n",
    "\n",
    "Z = []\n",
    "Z.append(img_to_array(img1))\n",
    "Z.append(img_to_array(img2))\n",
    "Z.append(img_to_array(img3))\n",
    "Z.append(img_to_array(img4))\n",
    "Z.append(img_to_array(img5))\n",
    "Z = np.array(Z)\n",
    "\n",
    "Z_pred_proba = model.predict(X_ts)\n",
    "Z_pred = np.round(Z_pred_proba)\n",
    "aux = 0\n",
    "for i in Z_pred:\n",
    "    imgplot = plt.imshow(array_to_img(X_ts[aux]))\n",
    "    plt.show()\n",
    "    aux += 1\n",
    "    if(i == 0):\n",
    "        print(\"Es Cobi\")\n",
    "    else:\n",
    "        print(\"No es Cobi\")\n",
    "    \n",
    "print(Z_pred_proba)\n",
    "print('')\n",
    "print(classification_report(Y_ts, Z_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
